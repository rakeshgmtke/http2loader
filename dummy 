func schedulerGlobal(
	ctx context.Context,
	totalTPS float64,
	apis []API,
	pending chan<- Job,
	totalMsg int,
	closePending func(),
) {
	// If no APIs, nothing to do
	if len(apis) == 0 {
		if closePending != nil {
			closePending()
		}
		return
	}

	ticker := time.NewTicker(1 * time.Millisecond)
	defer ticker.Stop()

	// Global TPS across all APIs
	// Example: TPS = 100 -> 100 / 1000 = 0.1 requests per millisecond
	rate := totalTPS / 1000.0

	var acc float64   // accumulator for fractional requests
	var sent int      // total messages sent so far
	apiIdx := 0       // round-robin index over APIs

	for {
		select {
		case <-ctx.Done():
			return

		case <-ticker.C:
			// If totalMsg > 0, stop once we reach it
			if totalMsg > 0 && sent >= totalMsg {
				logrus.Infof("[SCHED] reached total messages=%d, stopping scheduler", totalMsg)
				if closePending != nil {
					closePending()
				}
				return
			}

			// If TPS not set or zero, don't schedule anything
			if totalTPS <= 0 {
				continue
			}

			// Add per-ms rate into accumulator
			acc += rate

			// How many whole requests can we emit now?
			toEmit := int(math.Floor(acc))
			if toEmit <= 0 {
				continue
			}
			acc -= float64(toEmit)

			for i := 0; i < toEmit; i++ {
				// Check again so we don't exceed totalMsg
				if totalMsg > 0 && sent >= totalMsg {
					logrus.Infof("[SCHED] reached total messages=%d, stopping scheduler", totalMsg)
					if closePending != nil {
						closePending()
					}
					return
				}

				api := apis[apiIdx]
				apiIdx = (apiIdx + 1) % len(apis)

				seq := atomic.AddInt64(&globalSeq, 1)
				job := Job{
					API: api,
					Seq: seq,
				}

				select {
				case pending <- job:
					sent++
					logrus.Debugf("[SCHED] queued api=%s seq=%d sent=%d", api.Name, seq, sent)
				case <-ctx.Done():
					return
				}
			}
		}
	}
}